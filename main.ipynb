{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jinho-choi123/advanced-Grapher/blob/artifact-evaluation/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "7m-Qpa3sjKaF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C3SYImfQTjNI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d850682-d624-43e6-9815-ace9bb33bcb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ú®üç∞‚ú® Everything looks OK!\n"
          ]
        }
      ],
      "source": [
        "# Install Colab Conda\n",
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Git clone https://github.com/jinho-choi123/advanced-Grapher.git\n",
        "!GIT_LFS_SKIP_SMUDGE=1 git clone https://github.com/jinho-choi123/advanced-Grapher.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rs2WemMUjQ1E",
        "outputId": "d034a542-9c02-42b5-daf7-6440ced7558b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'advanced-Grapher'...\n",
            "remote: Enumerating objects: 2147, done.\u001b[K\n",
            "remote: Counting objects: 100% (36/36), done.\u001b[K\n",
            "remote: Compressing objects: 100% (26/26), done.\u001b[K\n",
            "remote: Total 2147 (delta 11), reused 27 (delta 6), pack-reused 2111 (from 2)\u001b[K\n",
            "Receiving objects: 100% (2147/2147), 41.26 MiB | 15.19 MiB/s, done.\n",
            "Resolving deltas: 100% (1227/1227), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# install conda dependencies\n",
        "# Takes about 15 minutes\n",
        "\n",
        "%cd advanced-Grapher\n",
        "\n",
        "!sh scripts/setup.sh"
      ],
      "metadata": {
        "id": "z0munEtujSCr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Grapher"
      ],
      "metadata": {
        "id": "2b389hyrjvjJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "eval \"$(conda shell.bash hook)\"\n",
        "conda activate advanced_grapher_env\n",
        "\n",
        "cat scripts/train_grapher.sh\n",
        "sh scripts/train_grapher.sh"
      ],
      "metadata": {
        "id": "Dh8I-mGljxEG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train GCN"
      ],
      "metadata": {
        "id": "SpUGC6x6xyKR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "eval \"$(conda shell.bash hook)\"\n",
        "conda activate advanced_grapher_env\n",
        "\n",
        "cat scripts/train_rgcn.sh\n",
        "sh scripts/train_rgcn.sh"
      ],
      "metadata": {
        "id": "9B-8fJK2xzxp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Grapher"
      ],
      "metadata": {
        "id": "QJ6pT6-Nj6N9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "# Takes about 3 minutes\n",
        "eval \"$(conda shell.bash hook)\"\n",
        "conda activate advanced_grapher_env\n",
        "\n",
        "cat scripts/test_grapher.sh\n",
        "sh scripts/test_grapher.sh"
      ],
      "metadata": {
        "id": "vXNnIlghj7Nx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "404fe9f4-c941-49b7-9b3c-0e0973071d84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#!/usr/bin/env bash\n",
            "\n",
            "# FIXME: for fast testing, limit_test_batches set to 0.1, at real-evaluation we should recover the value to 1.0\n",
            "python main.py    --version 1\\\n",
            "                  --default_root_dir output \\\n",
            "                  --run test \\\n",
            "                  --max_epochs 1 \\\n",
            "                  --accelerator gpu \\\n",
            "                  --num_nodes 1 \\\n",
            "                  --devices \"0,\" \\\n",
            "                  --batch_size 120 \\\n",
            "                  --num_sanity_val_steps 0 \\\n",
            "                  --fast_dev_run 0 \\\n",
            "                  --overfit_batches 0 \\\n",
            "                  --limit_train_batches 1.0 \\\n",
            "                  --limit_val_batches 1.0 \\\n",
            "                  --limit_test_batches 1.0 \\\n",
            "                  --accumulate_grad_batches 1 \\\n",
            "                  --detect_anomaly True \\\n",
            "                  --data_path webnlg-dataset/release_v3.0/en \\\n",
            "                  --checkpoint_model_id 79 \\\n",
            "                  --check_val_every_n_epoch 3 \\\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "TEST MODE\n",
            "Downloading: 100% 1.18k/1.18k [00:00<00:00, 3.58MB/s]\n",
            "Downloading: 100% 231M/231M [00:03<00:00, 71.0MB/s]\n",
            "add_rgcn not flagged.\n",
            "Freezed RGCN Model...\n",
            "Training Grapher Model...\n",
            "Downloading: 100% 2.27k/2.27k [00:00<00:00, 8.93MB/s]\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "`Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..\n",
            "`Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..\n",
            "`Trainer(limit_test_batches=1.0)` was configured so 100% of the batches will be used..\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Testing DataLoader 0: 100% 18/18 [00:54<00:00,  3.04s/it]creating reference xml  file : [output/webnlg_version_1/test/ref_0_0.xml]\n",
            "creating hypothesis xml file : [output/webnlg_version_1/test/hyp_0_0.xml]\n",
            "Testing DataLoader 0: 100% 18/18 [03:30<00:00, 11.69s/it]\n",
            "‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
            "‚îÉ\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m‚îÉ\n",
            "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
            "‚îÇ\u001b[36m \u001b[0m\u001b[36m           F1            \u001b[0m\u001b[36m \u001b[0m‚îÇ\u001b[35m \u001b[0m\u001b[35m   0.6024826765060425    \u001b[0m\u001b[35m \u001b[0m‚îÇ\n",
            "‚îÇ\u001b[36m \u001b[0m\u001b[36m        Precision        \u001b[0m\u001b[36m \u001b[0m‚îÇ\u001b[35m \u001b[0m\u001b[35m   0.5993416905403137    \u001b[0m\u001b[35m \u001b[0m‚îÇ\n",
            "‚îÇ\u001b[36m \u001b[0m\u001b[36m         Recall          \u001b[0m\u001b[36m \u001b[0m‚îÇ\u001b[35m \u001b[0m\u001b[35m   0.6073142290115356    \u001b[0m\u001b[35m \u001b[0m‚îÇ\n",
            "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test advanced Grapher"
      ],
      "metadata": {
        "id": "xv32LYsdx7Gb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "# Takes about 3 minutes\n",
        "\n",
        "eval \"$(conda shell.bash hook)\"\n",
        "conda activate advanced_grapher_env\n",
        "\n",
        "cat scripts/test_advanced_grapher.sh\n",
        "sh scripts/test_advanced_grapher.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWB3lmUcx_-6",
        "outputId": "58435a10-621b-44b4-e3b8-17341dbe3548"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#!/usr/bin/env bash\n",
            "\n",
            "# FIXME: for fast testing, limit_test_batches set to 0.1, at real-evaluation we should recover the value to 1.0\n",
            "python main.py    --version 1\\\n",
            "                  --default_root_dir output \\\n",
            "                  --run test \\\n",
            "                  --max_epochs 1 \\\n",
            "                  --accelerator gpu \\\n",
            "                  --num_nodes 1 \\\n",
            "                  --devices \"0,\" \\\n",
            "                  --batch_size 120 \\\n",
            "                  --num_sanity_val_steps 10 \\\n",
            "                  --fast_dev_run 0 \\\n",
            "                  --overfit_batches 0 \\\n",
            "                  --limit_train_batches 1.0 \\\n",
            "                  --limit_val_batches 1.0 \\\n",
            "                  --limit_test_batches 1.0 \\\n",
            "                  --accumulate_grad_batches 1 \\\n",
            "                  --detect_anomaly True \\\n",
            "                  --data_path webnlg-dataset/release_v3.0/en \\\n",
            "                  --checkpoint_model_id 114 \\\n",
            "                  --check_val_every_n_epoch 3 \\\n",
            "                  --add-rgcn  \\\n",
            "\n",
            "\n",
            "                  # set add_rgcn flag if you want to test with rgcn added\n",
            "                  # if add_rgcn flag is set, we should reduce batch_size\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "TEST MODE\n",
            "add_rgcn flagged.\n",
            "Freezed Grapher Model...\n",
            "Training RGCN Model...\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "`Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..\n",
            "`Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..\n",
            "`Trainer(limit_test_batches=1.0)` was configured so 100% of the batches will be used..\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Testing DataLoader 0: 100% 18/18 [00:54<00:00,  3.03s/it]creating reference xml  file : [output/webnlg_version_1/test/ref_0_0.xml]\n",
            "creating hypothesis xml file : [output/webnlg_version_1/test/hyp_0_0.xml]\n",
            "Testing DataLoader 0: 100% 18/18 [04:11<00:00, 13.95s/it]\n",
            "‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
            "‚îÉ\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m‚îÉ\n",
            "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
            "‚îÇ\u001b[36m \u001b[0m\u001b[36m           F1            \u001b[0m\u001b[36m \u001b[0m‚îÇ\u001b[35m \u001b[0m\u001b[35m   0.5894231796264648    \u001b[0m\u001b[35m \u001b[0m‚îÇ\n",
            "‚îÇ\u001b[36m \u001b[0m\u001b[36m        Precision        \u001b[0m\u001b[36m \u001b[0m‚îÇ\u001b[35m \u001b[0m\u001b[35m   0.5860973000526428    \u001b[0m\u001b[35m \u001b[0m‚îÇ\n",
            "‚îÇ\u001b[36m \u001b[0m\u001b[36m         Recall          \u001b[0m\u001b[36m \u001b[0m‚îÇ\u001b[35m \u001b[0m\u001b[35m   0.5947153568267822    \u001b[0m\u001b[35m \u001b[0m‚îÇ\n",
            "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Single Inference for Grapher"
      ],
      "metadata": {
        "id": "J7BG82oWyE9r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "eval \"$(conda shell.bash hook)\"\n",
        "conda activate advanced_grapher_env\n",
        "\n",
        "python main.py    --version 1\\\n",
        "                  --default_root_dir output \\\n",
        "                  --run inference \\\n",
        "                  --max_epochs 1 \\\n",
        "                  --accelerator gpu \\\n",
        "                  --num_nodes 1 \\\n",
        "                  --devices \"0,\" \\\n",
        "                  --batch_size 120 \\\n",
        "                  --num_sanity_val_steps 10 \\\n",
        "                  --fast_dev_run 0 \\\n",
        "                  --overfit_batches 0 \\\n",
        "                  --limit_train_batches 1.0 \\\n",
        "                  --limit_val_batches 1.0 \\\n",
        "                  --limit_test_batches 1.0 \\\n",
        "                  --accumulate_grad_batches 1 \\\n",
        "                  --detect_anomaly True \\\n",
        "                  --data_path webnlg-dataset/release_v3.0/en \\\n",
        "                  --checkpoint_model_id 79 \\\n",
        "                  --check_val_every_n_epoch 3 \\\n",
        "                  --inference_input_text \"Danielle Harris had a main role in Super Capers, a 98 minute long movie.\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VyuiCdSD3WG-",
        "outputId": "aa3b9458-1040-4cf7-bb5d-59817794a917"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "add_rgcn not flagged.\n",
            "Freezed RGCN Model...\n",
            "Training Grapher Model...\n",
            "Generated Graph: ['Super Capers (comicsCharacter)-->creator-->Danielle Harris']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Single Inference for Advanced Grapher"
      ],
      "metadata": {
        "id": "5FCdn46z4Mvg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "eval \"$(conda shell.bash hook)\"\n",
        "conda activate advanced_grapher_env\n",
        "\n",
        "python main.py    --version 1\\\n",
        "                  --default_root_dir output \\\n",
        "                  --run inference \\\n",
        "                  --max_epochs 1 \\\n",
        "                  --accelerator gpu \\\n",
        "                  --num_nodes 1 \\\n",
        "                  --devices \"0,\" \\\n",
        "                  --batch_size 120 \\\n",
        "                  --num_sanity_val_steps 10 \\\n",
        "                  --fast_dev_run 0 \\\n",
        "                  --overfit_batches 0 \\\n",
        "                  --limit_train_batches 1.0 \\\n",
        "                  --limit_val_batches 1.0 \\\n",
        "                  --limit_test_batches 1.0 \\\n",
        "                  --accumulate_grad_batches 1 \\\n",
        "                  --detect_anomaly True \\\n",
        "                  --data_path webnlg-dataset/release_v3.0/en \\\n",
        "                  --checkpoint_model_id 114 \\\n",
        "                  --check_val_every_n_epoch 3 \\\n",
        "                  --add-rgcn  \\\n",
        "                  --inference_input_text \"Danielle Harris had a main role in Super Capers, a 98 minute long movie.\"\n",
        "\n",
        "\n",
        "                  # set add_rgcn flag if you want to test with rgcn added\n",
        "                  # if add_rgcn flag is set, we should reduce batch_size\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2tUrA_WU4MJf",
        "outputId": "b9453f4e-c1b1-44e9-cee2-519b82196526"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "add_rgcn flagged.\n",
            "Freezed Grapher Model...\n",
            "Training RGCN Model...\n",
            "Generated Graph: ['Super Capers (comicsCharacter)-->length-->98\"(minutes)', 'Super Capers (comicsCharacter)-->creator-->Danielle Harris']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    }
  ]
}