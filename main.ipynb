{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyPosybBbkyswXEkNsgc6Ynk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jinho-choi123/advanced-Grapher/blob/egtr_method/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "7m-Qpa3sjKaF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "C3SYImfQTjNI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51e9a17c-cc02-440e-9a85-88c644bb804d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "â¬ Downloading https://github.com/jaimergp/miniforge/releases/download/24.11.2-1_colab/Miniforge3-colab-24.11.2-1_colab-Linux-x86_64.sh...\n",
            "ğŸ“¦ Installing...\n",
            "ğŸ“Œ Adjusting configuration...\n",
            "ğŸ©¹ Patching environment...\n",
            "â² Done in 0:00:06\n",
            "ğŸ” Restarting kernel...\n"
          ]
        }
      ],
      "source": [
        "# Install Colab Conda\n",
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Git clone https://github.com/jinho-choi123/advanced-Grapher.git\n",
        "!git clone https://github.com/jinho-choi123/advanced-Grapher.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rs2WemMUjQ1E",
        "outputId": "5801f109-24ea-478c-8244-3d1669c0d851"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'advanced-Grapher'...\n",
            "remote: Enumerating objects: 276, done.\u001b[K\n",
            "remote: Counting objects: 100% (67/67), done.\u001b[K\n",
            "remote: Compressing objects: 100% (46/46), done.\u001b[K\n",
            "remote: Total 276 (delta 44), reused 21 (delta 21), pack-reused 209 (from 2)\u001b[K\n",
            "Receiving objects: 100% (276/276), 21.76 MiB | 46.61 MiB/s, done.\n",
            "Resolving deltas: 100% (146/146), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# install conda dependencies\n",
        "%cd advanced-Grapher\n",
        "\n",
        "!conda env create -q -f requirements.yml -n advanced_grapher_env"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0munEtujSCr",
        "outputId": "647369b7-1699-4fd4-80ea-09769b1a8958"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/advanced-Grapher\n",
            "Channels:\n",
            " - pytorch\n",
            " - nvidia\n",
            " - conda-forge\n",
            " - defaults\n",
            "Platform: linux-64\n",
            "Collecting package metadata (repodata.json): ...working... done\n",
            "Solving environment: ...working... done\n",
            "Preparing transaction: ...working... done\n",
            "Verifying transaction: ...working... done\n",
            "Executing transaction: ...working... done\n",
            "Installing pip dependencies: ...working... done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "eval \"$(conda shell.bash hook)\"\n",
        "conda activate advanced_grapher_env"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebhEVyc4oRIH",
        "outputId": "42e403b5-a3c1-4db5-fb40-491435a2753c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# install datasets and dataset reader\n",
        "!git clone https://gitlab.com/webnlg/corpus-reader.git corpusreader\n",
        "!git clone https://gitlab.com/shimorina/webnlg-dataset.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JrAXHlszjq1q",
        "outputId": "c638f1a6-714d-4096-f3d7-81faf4bac620"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'corpusreader'...\n",
            "remote: Enumerating objects: 21, done.\u001b[K\n",
            "remote: Total 21 (delta 0), reused 0 (delta 0), pack-reused 21 (from 1)\u001b[K\n",
            "Receiving objects: 100% (21/21), 7.88 KiB | 7.88 MiB/s, done.\n",
            "Resolving deltas: 100% (9/9), done.\n",
            "Cloning into 'webnlg-dataset'...\n",
            "remote: Enumerating objects: 5112, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 5112 (delta 2), reused 0 (delta 0), pack-reused 5106 (from 1)\u001b[K\n",
            "Receiving objects: 100% (5112/5112), 26.09 MiB | 24.60 MiB/s, done.\n",
            "Resolving deltas: 100% (4010/4010), done.\n",
            "Updating files: 100% (1425/1425), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "2b389hyrjvjJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "eval \"$(conda shell.bash hook)\"\n",
        "conda activate advanced_grapher_env\n",
        "\n",
        "# Actual Training happens here\n",
        "python main.py    --version 1\\\n",
        "                  --default_root_dir output \\\n",
        "                  --run train \\\n",
        "                  --max_epochs 100 \\\n",
        "                  --accelerator gpu \\\n",
        "                  --num_nodes 1 \\\n",
        "                  --devices \"0,\" \\\n",
        "                  --num_data_workers 12 \\\n",
        "                  --lr 1e-4 \\\n",
        "                  --batch_size 200 \\\n",
        "                  --num_sanity_val_steps 10 \\\n",
        "                  --fast_dev_run 0 \\\n",
        "                  --overfit_batches 0 \\\n",
        "                  --limit_train_batches 1.0 \\\n",
        "                  --limit_val_batches 1.0 \\\n",
        "                  --limit_test_batches 1.0 \\\n",
        "                  --accumulate_grad_batches 1 \\\n",
        "                  --detect_anomaly True \\\n",
        "                  --data_path webnlg-dataset/release_v3.0/en \\\n",
        "                  --val_check_interval 1.0 \\\n",
        "                  --focal_loss_gamma 3 \\\n",
        "                  --dropout_rate 0.5 \\\n",
        "                  --num_layers 2 \\\n",
        "                  --edges_as_classes 1 \\\n",
        "                  --checkpoint_model_id -1 \\\n",
        "                  --check_val_every_n_epoch 10 \\\n",
        "                  # --add-rgcn\n",
        "\n",
        "\n",
        "                  # set add_rgcn flag if you want to test with rgcn added\n",
        "                  # if add_rgcn flag is set, we should reduce batch_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dh8I-mGljxEG",
        "outputId": "33dc85bd-475c-4be4-b05b-e4ab077c2592"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "('arguments: \\n'\n",
            " \"Namespace(dataset='webnlg', run='train', pretrained_model='t5-small', \"\n",
            " \"version='1', data_path='webnlg-dataset/release_v3.0/en', cache_dir='cache', \"\n",
            " 'num_data_workers=12, checkpoint_model_id=-1, max_nodes=8, max_edges=7, '\n",
            " 'default_seq_len_node=20, default_seq_len_edge=20, edges_as_classes=1, '\n",
            " 'batch_size=200, lr=0.0001, focal_loss_gamma=3.0, dropout_rate=0.5, '\n",
            " \"num_layers=2, eval_dump_only=0, inference_input_text='Danielle Harris had a \"\n",
            " \"main role in Super Capers, a 98 minute long movie.', model_max_length=512, \"\n",
            " 'rgcn_layers_num=2, rgcn_hidden_dim=128, add_rgcn=False, logger=True, '\n",
            " \"enable_checkpointing=True, default_root_dir='output', \"\n",
            " 'gradient_clip_val=None, gradient_clip_algorithm=None, num_nodes=1, '\n",
            " \"num_processes=None, devices='0,', gpus=None, auto_select_gpus=False, \"\n",
            " 'tpu_cores=None, ipus=None, enable_progress_bar=True, overfit_batches=0, '\n",
            " 'track_grad_norm=-1, check_val_every_n_epoch=10, fast_dev_run=False, '\n",
            " 'accumulate_grad_batches=1, max_epochs=100, min_epochs=None, max_steps=-1, '\n",
            " 'min_steps=None, max_time=None, limit_train_batches=1.0, '\n",
            " 'limit_val_batches=1.0, limit_test_batches=1.0, limit_predict_batches=None, '\n",
            " \"val_check_interval=1.0, log_every_n_steps=50, accelerator='gpu', \"\n",
            " 'strategy=None, sync_batchnorm=False, precision=32, '\n",
            " 'enable_model_summary=True, num_sanity_val_steps=10, '\n",
            " 'resume_from_checkpoint=None, profiler=None, benchmark=None, '\n",
            " 'deterministic=None, reload_dataloaders_every_n_epochs=0, auto_lr_find=False, '\n",
            " 'replace_sampler_ddp=True, detect_anomaly=True, auto_scale_batch_size=False, '\n",
            " \"plugins=None, amp_backend='native', amp_level=None, \"\n",
            " \"move_metrics_to_cpu=False, multiple_trainloader_mode='max_size_cycle', \"\n",
            " 'inference_mode=True)')\n",
            "TRAIN MODE\n",
            "ModelCheckpoint(save_last=True, save_top_k=-1, monitor=None) will duplicate the last checkpoint saved.\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "`Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..\n",
            "`Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..\n",
            "`Trainer(limit_test_batches=1.0)` was configured so 100% of the batches will be used..\n",
            "`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n",
            "/usr/local/envs/advanced_grapher_env/lib/python3.9/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:601: UserWarning: Checkpoint directory output/webnlg_version_1/checkpoints exists and is not empty.\n",
            "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
            "Restoring states from the checkpoint path at output/webnlg_version_1/checkpoints/last.ckpt\n",
            "/usr/local/envs/advanced_grapher_env/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1401: UserWarning: Be aware that when using `ckpt_path`, callbacks used to create the checkpoint need to be provided during `Trainer` instantiation. Please add the following callbacks: [\"ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None, 'save_on_train_epoch_end': True}\"].\n",
            "  rank_zero_warn(\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "â”â”â”â”â”³â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”“\n",
            "â”ƒ\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mName \u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mType   \u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\n",
            "â”¡â”â”â”â•‡â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”©\n",
            "â”‚\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0mâ”‚ model â”‚ Grapher â”‚ 61.3 M â”‚\n",
            "â””â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
            "\u001b[1mTrainable params\u001b[0m: 61.3 M                                                        \n",
            "\u001b[1mNon-trainable params\u001b[0m: 0                                                         \n",
            "\u001b[1mTotal params\u001b[0m: 61.3 M                                                            \n",
            "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 245                                     \n",
            "Restored all states from the checkpoint file at output/webnlg_version_1/checkpoints/last.ckpt\n",
            "\u001b[2Kcreating reference xml  file : [output/webnlg_version_1/valid/ref_1780_0.xml]\n",
            "\u001b[2Kcreating hypothesis xml file : [output/webnlg_version_1/valid/hyp_1780_0.xml]\n",
            "\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m0/178\u001b[0m \u001b[37m0:00:00 â€¢ -:--:--\u001b[0m \u001b[37m0.00it/s\u001b[0m \u001b[37mloss: nan v_num: \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m0/178\u001b[0m \u001b[37m0:00:01 â€¢ -:--:--\u001b[0m \u001b[37m0.00it/s\u001b[0m \u001b[37mloss: 0.309      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m0/178\u001b[0m \u001b[37m0:00:02 â€¢ -:--:--\u001b[0m \u001b[37m0.00it/s\u001b[0m \u001b[37mloss: 0.332      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m0/178\u001b[0m \u001b[37m0:00:03 â€¢ -:--:--\u001b[0m \u001b[37m0.00it/s\u001b[0m \u001b[37mloss: 0.354      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m0/178\u001b[0m \u001b[37m0:00:04 â€¢ -:--:--\u001b[0m \u001b[37m0.00it/s\u001b[0m \u001b[37mloss: 0.367      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m0/178\u001b[0m \u001b[37m0:00:05 â€¢ -:--:--\u001b[0m \u001b[37m0.00it/s\u001b[0m \u001b[37mloss: 0.367      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m0/178\u001b[0m \u001b[37m0:00:06 â€¢ -:--:--\u001b[0m \u001b[37m0.00it/s\u001b[0m \u001b[37mloss: 0.359      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m0/178\u001b[0m \u001b[37m0:00:07 â€¢ -:--:--\u001b[0m \u001b[37m0.00it/s\u001b[0m \u001b[37mloss: 0.367      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m0/178\u001b[0m \u001b[37m0:00:08 â€¢ -:--:--\u001b[0m \u001b[37m0.00it/s\u001b[0m \u001b[37mloss: 0.372      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m0/178\u001b[0m \u001b[37m0:00:09 â€¢ -:--:--\u001b[0m \u001b[37m0.00it/s\u001b[0m \u001b[37mloss: 0.368      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m10/178\u001b[0m \u001b[37m0:00:10 â€¢ -:--:--\u001b[0m \u001b[37m0.00it/s\u001b[0m \u001b[37mloss: 0.368      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m10/178\u001b[0m \u001b[37m0:00:10 â€¢ -:--:--\u001b[0m \u001b[37m0.00it/s\u001b[0m \u001b[37mloss: 0.365      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m10/178\u001b[0m \u001b[37m0:00:11 â€¢ -:--:--\u001b[0m \u001b[37m0.00it/s\u001b[0m \u001b[37mloss: 0.359      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m10/178\u001b[0m \u001b[37m0:00:13 â€¢ -:--:--\u001b[0m \u001b[37m0.00it/s\u001b[0m \u001b[37mloss: 0.355      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m10/178\u001b[0m \u001b[37m0:00:14 â€¢ -:--:--\u001b[0m \u001b[37m0.00it/s\u001b[0m \u001b[37mloss: 0.354      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m10/178\u001b[0m \u001b[37m0:00:15 â€¢ -:--:--\u001b[0m \u001b[37m0.00it/s\u001b[0m \u001b[37mloss: 0.353      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m10/178\u001b[0m \u001b[37m0:00:16 â€¢ -:--:--\u001b[0m \u001b[37m0.00it/s\u001b[0m \u001b[37mloss: 0.354      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m10/178\u001b[0m \u001b[37m0:00:17 â€¢ -:--:--\u001b[0m \u001b[37m0.00it/s\u001b[0m \u001b[37mloss: 0.353      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m10/178\u001b[0m \u001b[37m0:00:18 â€¢ -:--:--\u001b[0m \u001b[37m0.00it/s\u001b[0m \u001b[37mloss: 0.353      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m10/178\u001b[0m \u001b[37m0:00:19 â€¢ -:--:--\u001b[0m \u001b[37m0.00it/s\u001b[0m \u001b[37mloss: 0.356      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m10/178\u001b[0m \u001b[37m0:00:20 â€¢ -:--:--\u001b[0m \u001b[37m0.00it/s\u001b[0m \u001b[37mloss: 0.354      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ”\u001b[0m\u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m20/178\u001b[0m \u001b[37m0:00:21 â€¢ 0:02:50\u001b[0m \u001b[37m0.93it/s\u001b[0m \u001b[37mloss: 0.354      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ”\u001b[0m\u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m20/178\u001b[0m \u001b[37m0:00:21 â€¢ 0:02:50\u001b[0m \u001b[37m0.93it/s\u001b[0m \u001b[37mloss: 0.353      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ”\u001b[0m\u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m20/178\u001b[0m \u001b[37m0:00:22 â€¢ 0:02:50\u001b[0m \u001b[37m0.93it/s\u001b[0m \u001b[37mloss: 0.354      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ”\u001b[0m\u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m20/178\u001b[0m \u001b[37m0:00:23 â€¢ 0:02:50\u001b[0m \u001b[37m0.93it/s\u001b[0m \u001b[37mloss: 0.356      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ”\u001b[0m\u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m20/178\u001b[0m \u001b[37m0:00:24 â€¢ 0:02:50\u001b[0m \u001b[37m0.93it/s\u001b[0m \u001b[37mloss: 0.354      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ”\u001b[0m\u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m20/178\u001b[0m \u001b[37m0:00:25 â€¢ 0:02:50\u001b[0m \u001b[37m0.93it/s\u001b[0m \u001b[37mloss: 0.351      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ”\u001b[0m\u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m20/178\u001b[0m \u001b[37m0:00:26 â€¢ 0:02:50\u001b[0m \u001b[37m0.93it/s\u001b[0m \u001b[37mloss: 0.35 v_num:\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ”\u001b[0m\u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m20/178\u001b[0m \u001b[37m0:00:27 â€¢ 0:02:50\u001b[0m \u001b[37m0.93it/s\u001b[0m \u001b[37mloss: 0.351      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ”\u001b[0m\u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m20/178\u001b[0m \u001b[37m0:00:28 â€¢ 0:02:50\u001b[0m \u001b[37m0.93it/s\u001b[0m \u001b[37mloss: 0.352      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ”\u001b[0m\u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m20/178\u001b[0m \u001b[37m0:00:29 â€¢ 0:02:50\u001b[0m \u001b[37m0.93it/s\u001b[0m \u001b[37mloss: 0.351      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ”\u001b[0m\u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m20/178\u001b[0m \u001b[37m0:00:30 â€¢ 0:02:50\u001b[0m \u001b[37m0.93it/s\u001b[0m \u001b[37mloss: 0.354      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ”â”\u001b[0m\u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m30/178\u001b[0m \u001b[37m0:00:31 â€¢ 0:02:33\u001b[0m \u001b[37m0.97it/s\u001b[0m \u001b[37mloss: 0.354      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ”â”\u001b[0m\u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m30/178\u001b[0m \u001b[37m0:00:31 â€¢ 0:02:33\u001b[0m \u001b[37m0.97it/s\u001b[0m \u001b[37mloss: 0.354      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ”â”\u001b[0m\u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m30/178\u001b[0m \u001b[37m0:00:32 â€¢ 0:02:33\u001b[0m \u001b[37m0.97it/s\u001b[0m \u001b[37mloss: 0.358      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ”â”\u001b[0m\u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m30/178\u001b[0m \u001b[37m0:00:33 â€¢ 0:02:33\u001b[0m \u001b[37m0.97it/s\u001b[0m \u001b[37mloss: 0.361      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ”â”\u001b[0m\u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m30/178\u001b[0m \u001b[37m0:00:34 â€¢ 0:02:33\u001b[0m \u001b[37m0.97it/s\u001b[0m \u001b[37mloss: 0.362      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ”â”\u001b[0m\u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m30/178\u001b[0m \u001b[37m0:00:35 â€¢ 0:02:33\u001b[0m \u001b[37m0.97it/s\u001b[0m \u001b[37mloss: 0.362      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ”â”\u001b[0m\u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m30/178\u001b[0m \u001b[37m0:00:36 â€¢ 0:02:33\u001b[0m \u001b[37m0.97it/s\u001b[0m \u001b[37mloss: 0.366      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ”â”\u001b[0m\u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m30/178\u001b[0m \u001b[37m0:00:37 â€¢ 0:02:33\u001b[0m \u001b[37m0.97it/s\u001b[0m \u001b[37mloss: 0.364      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ”â”\u001b[0m\u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m30/178\u001b[0m \u001b[37m0:00:38 â€¢ 0:02:33\u001b[0m \u001b[37m0.97it/s\u001b[0m \u001b[37mloss: 0.363      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ”â”\u001b[0m\u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m30/178\u001b[0m \u001b[37m0:00:39 â€¢ 0:02:33\u001b[0m \u001b[37m0.97it/s\u001b[0m \u001b[37mloss: 0.362      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ”â”\u001b[0m\u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m30/178\u001b[0m \u001b[37m0:00:40 â€¢ 0:02:33\u001b[0m \u001b[37m0.97it/s\u001b[0m \u001b[37mloss: 0.361      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ”â”â”\u001b[0m\u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m40/178\u001b[0m \u001b[37m0:00:41 â€¢ 0:02:18\u001b[0m \u001b[37m1.01it/s\u001b[0m \u001b[37mloss: 0.361      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ”â”â”\u001b[0m\u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m40/178\u001b[0m \u001b[37m0:00:41 â€¢ 0:02:18\u001b[0m \u001b[37m1.01it/s\u001b[0m \u001b[37mloss: 0.361      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ”â”â”\u001b[0m\u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m40/178\u001b[0m \u001b[37m0:00:42 â€¢ 0:02:18\u001b[0m \u001b[37m1.01it/s\u001b[0m \u001b[37mloss: 0.362      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ”â”â”\u001b[0m\u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m40/178\u001b[0m \u001b[37m0:00:43 â€¢ 0:02:18\u001b[0m \u001b[37m1.01it/s\u001b[0m \u001b[37mloss: 0.359      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ”â”â”\u001b[0m\u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m40/178\u001b[0m \u001b[37m0:00:44 â€¢ 0:02:18\u001b[0m \u001b[37m1.01it/s\u001b[0m \u001b[37mloss: 0.357      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ”â”â”\u001b[0m\u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m40/178\u001b[0m \u001b[37m0:00:45 â€¢ 0:02:18\u001b[0m \u001b[37m1.01it/s\u001b[0m \u001b[37mloss: 0.359      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ”â”â”\u001b[0m\u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m40/178\u001b[0m \u001b[37m0:00:46 â€¢ 0:02:18\u001b[0m \u001b[37m1.01it/s\u001b[0m \u001b[37mloss: 0.358      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ”â”â”\u001b[0m\u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m40/178\u001b[0m \u001b[37m0:00:47 â€¢ 0:02:18\u001b[0m \u001b[37m1.01it/s\u001b[0m \u001b[37mloss: 0.362      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ”â”â”\u001b[0m\u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m40/178\u001b[0m \u001b[37m0:00:48 â€¢ 0:02:18\u001b[0m \u001b[37m1.01it/s\u001b[0m \u001b[37mloss: 0.355      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ”â”â”\u001b[0m\u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m40/178\u001b[0m \u001b[37m0:00:49 â€¢ 0:02:18\u001b[0m \u001b[37m1.01it/s\u001b[0m \u001b[37mloss: 0.352      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ”â”â”\u001b[0m\u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m40/178\u001b[0m \u001b[37m0:00:50 â€¢ 0:02:18\u001b[0m \u001b[37m1.01it/s\u001b[0m \u001b[37mloss: 0.353      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m50/178\u001b[0m \u001b[37m0:00:51 â€¢ 0:02:07\u001b[0m \u001b[37m1.01it/s\u001b[0m \u001b[37mloss: 0.353      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m50/178\u001b[0m \u001b[37m0:00:51 â€¢ 0:02:07\u001b[0m \u001b[37m1.01it/s\u001b[0m \u001b[37mloss: 0.353      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m50/178\u001b[0m \u001b[37m0:00:52 â€¢ 0:02:07\u001b[0m \u001b[37m1.01it/s\u001b[0m \u001b[37mloss: 0.351      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m50/178\u001b[0m \u001b[37m0:00:53 â€¢ 0:02:07\u001b[0m \u001b[37m1.01it/s\u001b[0m \u001b[37mloss: 0.35 v_num:\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m50/178\u001b[0m \u001b[37m0:00:54 â€¢ 0:02:07\u001b[0m \u001b[37m1.01it/s\u001b[0m \u001b[37mloss: 0.348      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m50/178\u001b[0m \u001b[37m0:00:55 â€¢ 0:02:07\u001b[0m \u001b[37m1.01it/s\u001b[0m \u001b[37mloss: 0.35 v_num:\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m50/178\u001b[0m \u001b[37m0:00:56 â€¢ 0:02:07\u001b[0m \u001b[37m1.01it/s\u001b[0m \u001b[37mloss: 0.345      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m50/178\u001b[0m \u001b[37m0:00:57 â€¢ 0:02:07\u001b[0m \u001b[37m1.01it/s\u001b[0m \u001b[37mloss: 0.346      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m50/178\u001b[0m \u001b[37m0:00:58 â€¢ 0:02:07\u001b[0m \u001b[37m1.01it/s\u001b[0m \u001b[37mloss: 0.345      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m50/178\u001b[0m \u001b[37m0:00:59 â€¢ 0:02:07\u001b[0m \u001b[37m1.01it/s\u001b[0m \u001b[37mloss: 0.345      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m50/178\u001b[0m \u001b[37m0:01:00 â€¢ 0:02:07\u001b[0m \u001b[37m1.01it/s\u001b[0m \u001b[37mloss: 0.349      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m60/178\u001b[0m \u001b[37m0:01:01 â€¢ 0:01:58\u001b[0m \u001b[37m1.01it/s\u001b[0m \u001b[37mloss: 0.349      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m60/178\u001b[0m \u001b[37m0:01:01 â€¢ 0:01:58\u001b[0m \u001b[37m1.01it/s\u001b[0m \u001b[37mloss: 0.349      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m60/178\u001b[0m \u001b[37m0:01:02 â€¢ 0:01:58\u001b[0m \u001b[37m1.01it/s\u001b[0m \u001b[37mloss: 0.347      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m60/178\u001b[0m \u001b[37m0:01:03 â€¢ 0:01:58\u001b[0m \u001b[37m1.01it/s\u001b[0m \u001b[37mloss: 0.346      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m60/178\u001b[0m \u001b[37m0:01:04 â€¢ 0:01:58\u001b[0m \u001b[37m1.01it/s\u001b[0m \u001b[37mloss: 0.348      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m60/178\u001b[0m \u001b[37m0:01:05 â€¢ 0:01:58\u001b[0m \u001b[37m1.01it/s\u001b[0m \u001b[37mloss: 0.347      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m60/178\u001b[0m \u001b[37m0:01:06 â€¢ 0:01:58\u001b[0m \u001b[37m1.01it/s\u001b[0m \u001b[37mloss: 0.35 v_num:\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m60/178\u001b[0m \u001b[37m0:01:07 â€¢ 0:01:58\u001b[0m \u001b[37m1.01it/s\u001b[0m \u001b[37mloss: 0.352      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m60/178\u001b[0m \u001b[37m0:01:08 â€¢ 0:01:58\u001b[0m \u001b[37m1.01it/s\u001b[0m \u001b[37mloss: 0.354      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m60/178\u001b[0m \u001b[37m0:01:09 â€¢ 0:01:58\u001b[0m \u001b[37m1.01it/s\u001b[0m \u001b[37mloss: 0.355      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m60/178\u001b[0m \u001b[37m0:01:10 â€¢ 0:01:58\u001b[0m \u001b[37m1.01it/s\u001b[0m \u001b[37mloss: 0.351      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m70/178\u001b[0m \u001b[37m0:01:11 â€¢ 0:01:47\u001b[0m \u001b[37m1.01it/s\u001b[0m \u001b[37mloss: 0.351      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m70/178\u001b[0m \u001b[37m0:01:11 â€¢ 0:01:47\u001b[0m \u001b[37m1.01it/s\u001b[0m \u001b[37mloss: 0.352      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m70/178\u001b[0m \u001b[37m0:01:11 â€¢ 0:01:47\u001b[0m \u001b[37m1.01it/s\u001b[0m \u001b[37mloss: 0.354      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m70/178\u001b[0m \u001b[37m0:01:13 â€¢ 0:01:47\u001b[0m \u001b[37m1.01it/s\u001b[0m \u001b[37mloss: 0.352      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m70/178\u001b[0m \u001b[37m0:01:13 â€¢ 0:01:47\u001b[0m \u001b[37m1.01it/s\u001b[0m \u001b[37mloss: 0.356      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m70/178\u001b[0m \u001b[37m0:01:14 â€¢ 0:01:47\u001b[0m \u001b[37m1.01it/s\u001b[0m \u001b[37mloss: 0.356      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m70/178\u001b[0m \u001b[37m0:01:15 â€¢ 0:01:47\u001b[0m \u001b[37m1.01it/s\u001b[0m \u001b[37mloss: 0.358      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m70/178\u001b[0m \u001b[37m0:01:17 â€¢ 0:01:47\u001b[0m \u001b[37m1.01it/s\u001b[0m \u001b[37mloss: 0.356      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m70/178\u001b[0m \u001b[37m0:01:18 â€¢ 0:01:47\u001b[0m \u001b[37m1.01it/s\u001b[0m \u001b[37mloss: 0.356      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m70/178\u001b[0m \u001b[37m0:01:19 â€¢ 0:01:47\u001b[0m \u001b[37m1.01it/s\u001b[0m \u001b[37mloss: 0.355      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m70/178\u001b[0m \u001b[37m0:01:20 â€¢ 0:01:47\u001b[0m \u001b[37m1.01it/s\u001b[0m \u001b[37mloss: 0.356      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”\u001b[0m \u001b[37m80/178\u001b[0m \u001b[37m0:01:21 â€¢ 0:01:38\u001b[0m \u001b[37m1.01it/s\u001b[0m \u001b[37mloss: 0.356      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”\u001b[0m \u001b[37m80/178\u001b[0m \u001b[37m0:01:21 â€¢ 0:01:38\u001b[0m \u001b[37m1.01it/s\u001b[0m \u001b[37mloss: 0.357      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”\u001b[0m \u001b[37m80/178\u001b[0m \u001b[37m0:01:21 â€¢ 0:01:38\u001b[0m \u001b[37m1.01it/s\u001b[0m \u001b[37mloss: 0.362      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”\u001b[0m \u001b[37m80/178\u001b[0m \u001b[37m0:01:23 â€¢ 0:01:38\u001b[0m \u001b[37m1.01it/s\u001b[0m \u001b[37mloss: 0.364      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”\u001b[0m \u001b[37m80/178\u001b[0m \u001b[37m0:01:24 â€¢ 0:01:38\u001b[0m \u001b[37m1.01it/s\u001b[0m \u001b[37mloss: 0.362      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”\u001b[0m \u001b[37m80/178\u001b[0m \u001b[37m0:01:25 â€¢ 0:01:38\u001b[0m \u001b[37m1.01it/s\u001b[0m \u001b[37mloss: 0.36 v_num:\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”\u001b[0m \u001b[37m80/178\u001b[0m \u001b[37m0:01:26 â€¢ 0:01:38\u001b[0m \u001b[37m1.01it/s\u001b[0m \u001b[37mloss: 0.356      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”\u001b[0m \u001b[37m80/178\u001b[0m \u001b[37m0:01:27 â€¢ 0:01:38\u001b[0m \u001b[37m1.01it/s\u001b[0m \u001b[37mloss: 0.351      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”\u001b[0m \u001b[37m80/178\u001b[0m \u001b[37m0:01:28 â€¢ 0:01:38\u001b[0m \u001b[37m1.01it/s\u001b[0m \u001b[37mloss: 0.348      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”\u001b[0m \u001b[37m80/178\u001b[0m \u001b[37m0:01:29 â€¢ 0:01:38\u001b[0m \u001b[37m1.01it/s\u001b[0m \u001b[37mloss: 0.346      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”\u001b[0m \u001b[37m80/178\u001b[0m \u001b[37m0:01:30 â€¢ 0:01:38\u001b[0m \u001b[37m1.01it/s\u001b[0m \u001b[37mloss: 0.348      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ”â”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”\u001b[0m \u001b[37m90/178\u001b[0m \u001b[37m0:01:31 â€¢ 0:01:28\u001b[0m \u001b[37m1.01it/s\u001b[0m \u001b[37mloss: 0.348      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ”â”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”\u001b[0m \u001b[37m90/178\u001b[0m \u001b[37m0:01:31 â€¢ 0:01:28\u001b[0m \u001b[37m1.01it/s\u001b[0m \u001b[37mloss: 0.346      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ”â”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”\u001b[0m \u001b[37m90/178\u001b[0m \u001b[37m0:01:32 â€¢ 0:01:28\u001b[0m \u001b[37m1.01it/s\u001b[0m \u001b[37mloss: 0.343      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ”â”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”\u001b[0m \u001b[37m90/178\u001b[0m \u001b[37m0:01:33 â€¢ 0:01:28\u001b[0m \u001b[37m1.01it/s\u001b[0m \u001b[37mloss: 0.342      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ”â”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”\u001b[0m \u001b[37m90/178\u001b[0m \u001b[37m0:01:33 â€¢ 0:01:28\u001b[0m \u001b[37m1.01it/s\u001b[0m \u001b[37mloss: 0.342      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ”â”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”\u001b[0m \u001b[37m90/178\u001b[0m \u001b[37m0:01:34 â€¢ 0:01:28\u001b[0m \u001b[37m1.01it/s\u001b[0m \u001b[37mloss: 0.341      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ”â”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”\u001b[0m \u001b[37m90/178\u001b[0m \u001b[37m0:01:36 â€¢ 0:01:28\u001b[0m \u001b[37m1.01it/s\u001b[0m \u001b[37mloss: 0.339      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ”â”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”\u001b[0m \u001b[37m90/178\u001b[0m \u001b[37m0:01:37 â€¢ 0:01:28\u001b[0m \u001b[37m1.01it/s\u001b[0m \u001b[37mloss: 0.341      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ”â”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”\u001b[0m \u001b[37m90/178\u001b[0m \u001b[37m0:01:38 â€¢ 0:01:28\u001b[0m \u001b[37m1.01it/s\u001b[0m \u001b[37mloss: 0.344      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ”â”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”\u001b[0m \u001b[37m90/178\u001b[0m \u001b[37m0:01:38 â€¢ 0:01:28\u001b[0m \u001b[37m1.01it/s\u001b[0m \u001b[37mloss: 0.347      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ”â”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”\u001b[0m \u001b[37m90/178\u001b[0m \u001b[37m0:01:39 â€¢ 0:01:28\u001b[0m \u001b[37m1.01it/s\u001b[0m \u001b[37mloss: 0.342      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ”â”â”â”â”â”â”â”\u001b[0m\u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”\u001b[0m \u001b[37m100/178\u001b[0m \u001b[37m0:01:40 â€¢       \u001b[0m \u001b[37m1.01it/s\u001b[0m \u001b[37mloss: 0.342      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ”â”â”â”â”â”â”â”\u001b[0m\u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”\u001b[0m \u001b[37m100/178\u001b[0m \u001b[37m0:01:40 â€¢       \u001b[0m \u001b[37m1.01it/s\u001b[0m \u001b[37mloss: 0.344      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ”â”â”â”â”â”â”â”\u001b[0m\u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”\u001b[0m \u001b[37m100/178\u001b[0m \u001b[37m0:01:41 â€¢       \u001b[0m \u001b[37m1.01it/s\u001b[0m \u001b[37mloss: 0.34 v_num:\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ”â”â”â”â”â”â”â”\u001b[0m\u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”\u001b[0m \u001b[37m100/178\u001b[0m \u001b[37m0:01:42 â€¢       \u001b[0m \u001b[37m1.01it/s\u001b[0m \u001b[37mloss: 0.339      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ”â”â”â”â”â”â”â”\u001b[0m\u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”\u001b[0m \u001b[37m100/178\u001b[0m \u001b[37m0:01:43 â€¢       \u001b[0m \u001b[37m1.01it/s\u001b[0m \u001b[37mloss: 0.339      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ”â”â”â”â”â”â”â”\u001b[0m\u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”\u001b[0m \u001b[37m100/178\u001b[0m \u001b[37m0:01:44 â€¢       \u001b[0m \u001b[37m1.01it/s\u001b[0m \u001b[37mloss: 0.339      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ”â”â”â”â”â”â”â”\u001b[0m\u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”\u001b[0m \u001b[37m100/178\u001b[0m \u001b[37m0:01:45 â€¢       \u001b[0m \u001b[37m1.01it/s\u001b[0m \u001b[37mloss: 0.341      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ”â”â”â”â”â”â”â”\u001b[0m\u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”\u001b[0m \u001b[37m100/178\u001b[0m \u001b[37m0:01:46 â€¢       \u001b[0m \u001b[37m1.01it/s\u001b[0m \u001b[37mloss: 0.34 v_num:\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ”â”â”â”â”â”â”â”\u001b[0m\u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”\u001b[0m \u001b[37m100/178\u001b[0m \u001b[37m0:01:48 â€¢       \u001b[0m \u001b[37m1.01it/s\u001b[0m \u001b[37mloss: 0.341      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ”â”â”â”â”â”â”â”\u001b[0m\u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”\u001b[0m \u001b[37m100/178\u001b[0m \u001b[37m0:01:48 â€¢       \u001b[0m \u001b[37m1.01it/s\u001b[0m \u001b[37mloss: 0.343      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ”â”â”â”â”â”â”â”\u001b[0m\u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”\u001b[0m \u001b[37m100/178\u001b[0m \u001b[37m0:01:49 â€¢       \u001b[0m \u001b[37m1.01it/s\u001b[0m \u001b[37mloss: 0.344      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ”â”â”â”â”â”â”â”â”\u001b[0m\u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”\u001b[0m \u001b[37m110/178\u001b[0m \u001b[37m0:01:50 â€¢       \u001b[0m \u001b[37m1.01it/s\u001b[0m \u001b[37mloss: 0.344      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ”â”â”â”â”â”â”â”â”\u001b[0m\u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”\u001b[0m \u001b[37m110/178\u001b[0m \u001b[37m0:01:50 â€¢       \u001b[0m \u001b[37m1.01it/s\u001b[0m \u001b[37mloss: 0.346      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ”â”â”â”â”â”â”â”â”\u001b[0m\u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”\u001b[0m \u001b[37m110/178\u001b[0m \u001b[37m0:01:51 â€¢       \u001b[0m \u001b[37m1.01it/s\u001b[0m \u001b[37mloss: 0.347      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ”â”â”â”â”â”â”â”â”\u001b[0m\u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”\u001b[0m \u001b[37m110/178\u001b[0m \u001b[37m0:01:52 â€¢       \u001b[0m \u001b[37m1.01it/s\u001b[0m \u001b[37mloss: 0.351      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ”â”â”â”â”â”â”â”â”\u001b[0m\u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”\u001b[0m \u001b[37m110/178\u001b[0m \u001b[37m0:01:53 â€¢       \u001b[0m \u001b[37m1.01it/s\u001b[0m \u001b[37mloss: 0.347      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ”â”â”â”â”â”â”â”â”\u001b[0m\u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”\u001b[0m \u001b[37m110/178\u001b[0m \u001b[37m0:01:54 â€¢       \u001b[0m \u001b[37m1.01it/s\u001b[0m \u001b[37mloss: 0.347      \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 10/99\u001b[0m \u001b[35mâ”â”â”â”â”â”â”â”â”\u001b[0m\u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”\u001b[0m \u001b[37m110/178\u001b[0m \u001b[37m0:01:55 â€¢       \u001b[0m \u001b[37m1.01it/s\u001b[0m \u001b[37mloss: 0.344      \u001b[0m\n",
            "                                     \u001b[37m0:01:08         \u001b[0m          \u001b[37mv_num: on_1      \u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing"
      ],
      "metadata": {
        "id": "QJ6pT6-Nj6N9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "eval \"$(conda shell.bash hook)\"\n",
        "conda activate advanced_grapher_env\n",
        "\n",
        "! python main.py  --version 1\\\n",
        "                  --default_root_dir output \\\n",
        "                  --run test \\\n",
        "                  --max_epochs 200 \\\n",
        "                  --accelerator gpu \\\n",
        "                  --num_nodes 1 \\\n",
        "                  --devices \"1,\" \\\n",
        "                  --num_data_workers 32 \\\n",
        "                  --lr 5e-4 \\\n",
        "                  --batch_size 150 \\\n",
        "                  --num_sanity_val_steps 0 \\\n",
        "                  --fast_dev_run 0 \\\n",
        "                  --overfit_batches 0 \\\n",
        "                  --limit_train_batches 1.0 \\\n",
        "                  --limit_val_batches 1.0 \\\n",
        "                  --limit_test_batches 1.0 \\\n",
        "                  --accumulate_grad_batches 1 \\\n",
        "                  --detect_anomaly True \\\n",
        "                  --data_path webnlg-dataset/release_v3.0/en \\\n",
        "                  --val_check_interval 1.0 \\\n",
        "                  --focal_loss_gamma 3 \\\n",
        "                  --dropout_rate 0.5 \\\n",
        "                  --num_layers 2 \\\n",
        "                  --checkpoint_model_id -1 \\\n",
        "                  --precision \"bf16\" \\\n",
        "                  # --add-rgcn  \\\n",
        "\n",
        "\n",
        "                  # set add_rgcn flag if you want to train rgcn"
      ],
      "metadata": {
        "id": "vXNnIlghj7Nx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}