{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNFR6h0K38K1mPlFJSZa2ER",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jinho-choi123/advanced-Grapher/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "7m-Qpa3sjKaF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "C3SYImfQTjNI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cef28ee-d4e9-4cc5-bf5f-86f22c3af51d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ¨ğŸ°âœ¨ Everything looks OK!\n"
          ]
        }
      ],
      "source": [
        "# Install Colab Conda\n",
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Git clone https://github.com/jinho-choi123/advanced-Grapher.git\n",
        "!git clone https://github.com/jinho-choi123/advanced-Grapher.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rs2WemMUjQ1E",
        "outputId": "421098a5-0e0f-483e-b2fc-b25c806857fa"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'advanced-Grapher' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "1nl1rs_crzee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# install conda dependencies\n",
        "%cd advanced-Grapher\n",
        "\n",
        "!conda env create -q -f requirements.yml -n advanced_grapher_env"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0munEtujSCr",
        "outputId": "17b02dcf-e907-4cbc-c73f-8b712970372d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'advanced-Grapher'\n",
            "/content/advanced-Grapher\n",
            "no change     /usr/local/condabin/conda\n",
            "no change     /usr/local/bin/conda\n",
            "no change     /usr/local/bin/conda-env\n",
            "no change     /usr/local/bin/activate\n",
            "no change     /usr/local/bin/deactivate\n",
            "no change     /usr/local/etc/profile.d/conda.sh\n",
            "no change     /usr/local/etc/fish/conf.d/conda.fish\n",
            "no change     /usr/local/shell/condabin/Conda.psm1\n",
            "no change     /usr/local/shell/condabin/conda-hook.ps1\n",
            "no change     /usr/local/lib/python3.11/site-packages/xontrib/conda.xsh\n",
            "no change     /usr/local/etc/profile.d/conda.csh\n",
            "no change     /root/.bashrc\n",
            "No action taken.\n",
            "\n",
            "CondaValueError: prefix already exists: /usr/local/envs/advanced_grapher_env\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "eval \"$(conda shell.bash hook)\"\n",
        "conda activate advanced_grapher_env"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebhEVyc4oRIH",
        "outputId": "ae68c8c0-e5fc-4502-8ead-ec6c8939502f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# install datasets and dataset reader\n",
        "!git clone https://gitlab.com/webnlg/corpus-reader.git corpusreader\n",
        "!git clone https://gitlab.com/shimorina/webnlg-dataset.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JrAXHlszjq1q",
        "outputId": "4a847a3b-bfa3-4c5b-f9c0-19bfb1dc4342"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'corpusreader'...\n",
            "remote: Enumerating objects: 21, done.\u001b[K\n",
            "remote: Total 21 (delta 0), reused 0 (delta 0), pack-reused 21 (from 1)\u001b[K\n",
            "Receiving objects: 100% (21/21), 7.88 KiB | 7.88 MiB/s, done.\n",
            "Resolving deltas: 100% (9/9), done.\n",
            "Cloning into 'webnlg-dataset'...\n",
            "remote: Enumerating objects: 5112, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 5112 (delta 2), reused 0 (delta 0), pack-reused 5106 (from 1)\u001b[K\n",
            "Receiving objects: 100% (5112/5112), 26.09 MiB | 20.10 MiB/s, done.\n",
            "Resolving deltas: 100% (4010/4010), done.\n",
            "Updating files: 100% (1425/1425), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "2b389hyrjvjJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "eval \"$(conda shell.bash hook)\"\n",
        "conda activate advanced_grapher_env\n",
        "\n",
        "# Actual Training happens here\n",
        "python main.py    --version 1\\\n",
        "                  --default_root_dir output \\\n",
        "                  --run train \\\n",
        "                  --max_epochs 100 \\\n",
        "                  --accelerator gpu \\\n",
        "                  --num_nodes 1 \\\n",
        "                  --devices \"0,\" \\\n",
        "                  --num_data_workers 2 \\\n",
        "                  --lr 1e-4 \\\n",
        "                  --batch_size 70 \\\n",
        "                  --num_sanity_val_steps 10 \\\n",
        "                  --fast_dev_run 0 \\\n",
        "                  --overfit_batches 0 \\\n",
        "                  --limit_train_batches 1.0 \\\n",
        "                  --limit_val_batches 1.0 \\\n",
        "                  --limit_test_batches 1.0 \\\n",
        "                  --accumulate_grad_batches 2 \\\n",
        "                  --detect_anomaly True \\\n",
        "                  --data_path webnlg-dataset/release_v3.0/en \\\n",
        "                  --val_check_interval 1.0 \\\n",
        "                  --focal_loss_gamma 3 \\\n",
        "                  --dropout_rate 0.5 \\\n",
        "                  --num_layers 2 \\\n",
        "                  --edges_as_classes 1 \\\n",
        "                  --checkpoint_model_id -1 \\\n",
        "\n",
        "\n",
        "                  # set add_rgcn flag if you want to test with rgcn added\n",
        "                  # if add_rgcn flag is set, we should reduce batch_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dh8I-mGljxEG",
        "outputId": "c045429f-41f4-4a8c-d124-dedbc715588a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "('arguments: \\n'\n",
            " \"Namespace(dataset='webnlg', run='train', pretrained_model='t5-small', \"\n",
            " \"version='1', data_path='webnlg-dataset/release_v3.0/en', cache_dir='cache', \"\n",
            " 'num_data_workers=2, checkpoint_model_id=-1, max_nodes=8, max_edges=7, '\n",
            " 'default_seq_len_node=20, default_seq_len_edge=20, edges_as_classes=1, '\n",
            " 'batch_size=70, lr=0.0001, focal_loss_gamma=3.0, dropout_rate=0.5, '\n",
            " \"num_layers=2, eval_dump_only=0, inference_input_text='Danielle Harris had a \"\n",
            " \"main role in Super Capers, a 98 minute long movie.', model_max_length=512, \"\n",
            " 'rgcn_layers_num=2, rgcn_hidden_dim=128, add_rgcn=False, logger=True, '\n",
            " \"enable_checkpointing=True, default_root_dir='output', \"\n",
            " 'gradient_clip_val=None, gradient_clip_algorithm=None, num_nodes=1, '\n",
            " \"num_processes=None, devices='0,', gpus=None, auto_select_gpus=False, \"\n",
            " 'tpu_cores=None, ipus=None, enable_progress_bar=True, overfit_batches=0, '\n",
            " 'track_grad_norm=-1, check_val_every_n_epoch=1, fast_dev_run=False, '\n",
            " 'accumulate_grad_batches=2, max_epochs=100, min_epochs=None, max_steps=-1, '\n",
            " 'min_steps=None, max_time=None, limit_train_batches=1.0, '\n",
            " 'limit_val_batches=1.0, limit_test_batches=1.0, limit_predict_batches=None, '\n",
            " \"val_check_interval=1.0, log_every_n_steps=50, accelerator='gpu', \"\n",
            " 'strategy=None, sync_batchnorm=False, precision=32, '\n",
            " 'enable_model_summary=True, num_sanity_val_steps=10, '\n",
            " 'resume_from_checkpoint=None, profiler=None, benchmark=None, '\n",
            " 'deterministic=None, reload_dataloaders_every_n_epochs=0, auto_lr_find=False, '\n",
            " 'replace_sampler_ddp=True, detect_anomaly=True, auto_scale_batch_size=False, '\n",
            " \"plugins=None, amp_backend='native', amp_level=None, \"\n",
            " \"move_metrics_to_cpu=False, multiple_trainloader_mode='max_size_cycle', \"\n",
            " 'inference_mode=True)')\n",
            "TRAIN MODE\n",
            "ModelCheckpoint(save_last=True, save_top_k=-1, monitor=None) will duplicate the last checkpoint saved.\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "`Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..\n",
            "`Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..\n",
            "`Trainer(limit_test_batches=1.0)` was configured so 100% of the batches will be used..\n",
            "`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "â”â”â”â”â”³â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”“\n",
            "â”ƒ\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mName \u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mType   \u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\n",
            "â”¡â”â”â”â•‡â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”©\n",
            "â”‚\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0mâ”‚ model â”‚ Grapher â”‚ 61.3 M â”‚\n",
            "â””â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
            "\u001b[1mTrainable params\u001b[0m: 61.3 M                                                        \n",
            "\u001b[1mNon-trainable params\u001b[0m: 0                                                         \n",
            "\u001b[1mTotal params\u001b[0m: 61.3 M                                                            \n",
            "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 245                                     \n",
            "\u001b[2Kcreating reference xml  file : [output/webnlg_version_1/valid/ref_0_0.xml]\n",
            "\u001b[2Kcreating hypothesis xml file : [output/webnlg_version_1/valid/hyp_0_0.xml]\n",
            "\u001b[2K\u001b[37mEpoch 0/99\u001b[0m \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m0/571\u001b[0m \u001b[37m0:00:00 â€¢ -:--:--\u001b[0m \u001b[37m0.00it/s\u001b[0m \u001b[37mloss: nan v_num:  \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0/99\u001b[0m \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m0/571\u001b[0m \u001b[37m0:00:01 â€¢ -:--:--\u001b[0m \u001b[37m0.00it/s\u001b[0m \u001b[37mloss: 15.2 v_num: \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0/99\u001b[0m \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m0/571\u001b[0m \u001b[37m0:00:02 â€¢ -:--:--\u001b[0m \u001b[37m0.00it/s\u001b[0m \u001b[37mloss: 14.2 v_num: \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0/99\u001b[0m \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m0/571\u001b[0m \u001b[37m0:00:03 â€¢ -:--:--\u001b[0m \u001b[37m0.00it/s\u001b[0m \u001b[37mloss: 14.3 v_num: \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0/99\u001b[0m \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m0/571\u001b[0m \u001b[37m0:00:04 â€¢ -:--:--\u001b[0m \u001b[37m0.00it/s\u001b[0m \u001b[37mloss: 14 v_num:   \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0/99\u001b[0m \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m0/571\u001b[0m \u001b[37m0:00:05 â€¢ -:--:--\u001b[0m \u001b[37m0.00it/s\u001b[0m \u001b[37mloss: 14.5 v_num: \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0/99\u001b[0m \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m0/571\u001b[0m \u001b[37m0:00:06 â€¢ -:--:--\u001b[0m \u001b[37m0.00it/s\u001b[0m \u001b[37mloss: 14.5 v_num: \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0/99\u001b[0m \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m0/571\u001b[0m \u001b[37m0:00:07 â€¢ -:--:--\u001b[0m \u001b[37m0.00it/s\u001b[0m \u001b[37mloss: 14.5 v_num: \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0/99\u001b[0m \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m0/571\u001b[0m \u001b[37m0:00:08 â€¢ -:--:--\u001b[0m \u001b[37m0.00it/s\u001b[0m \u001b[37mloss: 14.2 v_num: \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0/99\u001b[0m \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m0/571\u001b[0m \u001b[37m0:00:09 â€¢ -:--:--\u001b[0m \u001b[37m0.00it/s\u001b[0m \u001b[37mloss: 14.1 v_num: \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0/99\u001b[0m \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m10/571\u001b[0m \u001b[37m0:00:10 â€¢ -:--:--\u001b[0m \u001b[37m0.00it/s\u001b[0m \u001b[37mloss: 14.1 v_num:\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0/99\u001b[0m \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m10/571\u001b[0m \u001b[37m0:00:10 â€¢ -:--:--\u001b[0m \u001b[37m0.00it/s\u001b[0m \u001b[37mloss: 14.2 v_num:\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0/99\u001b[0m \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m10/571\u001b[0m \u001b[37m0:00:11 â€¢ -:--:--\u001b[0m \u001b[37m0.00it/s\u001b[0m \u001b[37mloss: 14 v_num:  \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0/99\u001b[0m \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m10/571\u001b[0m \u001b[37m0:00:13 â€¢ -:--:--\u001b[0m \u001b[37m0.00it/s\u001b[0m \u001b[37mloss: 14 v_num:  \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0/99\u001b[0m \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m10/571\u001b[0m \u001b[37m0:00:14 â€¢ -:--:--\u001b[0m \u001b[37m0.00it/s\u001b[0m \u001b[37mloss: 13.8 v_num:\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0/99\u001b[0m \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m10/571\u001b[0m \u001b[37m0:00:15 â€¢ -:--:--\u001b[0m \u001b[37m0.00it/s\u001b[0m \u001b[37mloss: 13.8 v_num:\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0/99\u001b[0m \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m10/571\u001b[0m \u001b[37m0:00:16 â€¢ -:--:--\u001b[0m \u001b[37m0.00it/s\u001b[0m \u001b[37mloss: 13.7 v_num:\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0/99\u001b[0m \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m10/571\u001b[0m \u001b[37m0:00:17 â€¢ -:--:--\u001b[0m \u001b[37m0.00it/s\u001b[0m \u001b[37mloss: 13.7 v_num:\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0/99\u001b[0m \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m10/571\u001b[0m \u001b[37m0:00:18 â€¢ -:--:--\u001b[0m \u001b[37m0.00it/s\u001b[0m \u001b[37mloss: 13.6 v_num:\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0/99\u001b[0m \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m10/571\u001b[0m \u001b[37m0:00:19 â€¢ -:--:--\u001b[0m \u001b[37m0.00it/s\u001b[0m \u001b[37mloss: 13.6 v_num:\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0/99\u001b[0m \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m10/571\u001b[0m \u001b[37m0:00:19 â€¢ -:--:--\u001b[0m \u001b[37m0.00it/s\u001b[0m \u001b[37mloss: 13.6 v_num:\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0/99\u001b[0m \u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m20/571\u001b[0m \u001b[37m0:00:21 â€¢ 0:09:43\u001b[0m \u001b[37m0.95it/s\u001b[0m \u001b[37mloss: 13.6 v_num:\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0/99\u001b[0m \u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m20/571\u001b[0m \u001b[37m0:00:21 â€¢ 0:09:43\u001b[0m \u001b[37m0.95it/s\u001b[0m \u001b[37mloss: 13.5 v_num:\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0/99\u001b[0m \u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m20/571\u001b[0m \u001b[37m0:00:22 â€¢ 0:09:43\u001b[0m \u001b[37m0.95it/s\u001b[0m \u001b[37mloss: 13.3 v_num:\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0/99\u001b[0m \u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m20/571\u001b[0m \u001b[37m0:00:23 â€¢ 0:09:43\u001b[0m \u001b[37m0.95it/s\u001b[0m \u001b[37mloss: 13.2 v_num:\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0/99\u001b[0m \u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m20/571\u001b[0m \u001b[37m0:00:24 â€¢ 0:09:43\u001b[0m \u001b[37m0.95it/s\u001b[0m \u001b[37mloss: 13.1 v_num:\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0/99\u001b[0m \u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m20/571\u001b[0m \u001b[37m0:00:25 â€¢ 0:09:43\u001b[0m \u001b[37m0.95it/s\u001b[0m \u001b[37mloss: 13.1 v_num:\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0/99\u001b[0m \u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m20/571\u001b[0m \u001b[37m0:00:26 â€¢ 0:09:43\u001b[0m \u001b[37m0.95it/s\u001b[0m \u001b[37mloss: 13 v_num:  \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0/99\u001b[0m \u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m20/571\u001b[0m \u001b[37m0:00:27 â€¢ 0:09:43\u001b[0m \u001b[37m0.95it/s\u001b[0m \u001b[37mloss: 12.8 v_num:\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0/99\u001b[0m \u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m20/571\u001b[0m \u001b[37m0:00:28 â€¢ 0:09:43\u001b[0m \u001b[37m0.95it/s\u001b[0m \u001b[37mloss: 12.6 v_num:\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0/99\u001b[0m \u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m20/571\u001b[0m \u001b[37m0:00:29 â€¢ 0:09:43\u001b[0m \u001b[37m0.95it/s\u001b[0m \u001b[37mloss: 12.6 v_num:\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0/99\u001b[0m \u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m20/571\u001b[0m \u001b[37m0:00:30 â€¢ 0:09:43\u001b[0m \u001b[37m0.95it/s\u001b[0m \u001b[37mloss: 12.6 v_num:\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0/99\u001b[0m \u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m30/571\u001b[0m \u001b[37m0:00:31 â€¢ 0:09:32\u001b[0m \u001b[37m0.95it/s\u001b[0m \u001b[37mloss: 12.6 v_num:\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0/99\u001b[0m \u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m30/571\u001b[0m \u001b[37m0:00:31 â€¢ 0:09:32\u001b[0m \u001b[37m0.95it/s\u001b[0m \u001b[37mloss: 12.5 v_num:\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0/99\u001b[0m \u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m30/571\u001b[0m \u001b[37m0:00:32 â€¢ 0:09:32\u001b[0m \u001b[37m0.95it/s\u001b[0m \u001b[37mloss: 12.5 v_num:\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0/99\u001b[0m \u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m30/571\u001b[0m \u001b[37m0:00:33 â€¢ 0:09:32\u001b[0m \u001b[37m0.95it/s\u001b[0m \u001b[37mloss: 12.4 v_num:\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0/99\u001b[0m \u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m30/571\u001b[0m \u001b[37m0:00:34 â€¢ 0:09:32\u001b[0m \u001b[37m0.95it/s\u001b[0m \u001b[37mloss: 12.4 v_num:\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0/99\u001b[0m \u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m30/571\u001b[0m \u001b[37m0:00:35 â€¢ 0:09:32\u001b[0m \u001b[37m0.95it/s\u001b[0m \u001b[37mloss: 12.4 v_num:\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0/99\u001b[0m \u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m30/571\u001b[0m \u001b[37m0:00:36 â€¢ 0:09:32\u001b[0m \u001b[37m0.95it/s\u001b[0m \u001b[37mloss: 12.4 v_num:\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0/99\u001b[0m \u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m30/571\u001b[0m \u001b[37m0:00:37 â€¢ 0:09:32\u001b[0m \u001b[37m0.95it/s\u001b[0m \u001b[37mloss: 12.3 v_num:\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0/99\u001b[0m \u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m30/571\u001b[0m \u001b[37m0:00:38 â€¢ 0:09:32\u001b[0m \u001b[37m0.95it/s\u001b[0m \u001b[37mloss: 12.2 v_num:\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0/99\u001b[0m \u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m30/571\u001b[0m \u001b[37m0:00:39 â€¢ 0:09:32\u001b[0m \u001b[37m0.95it/s\u001b[0m \u001b[37mloss: 12.1 v_num:\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0/99\u001b[0m \u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m30/571\u001b[0m \u001b[37m0:00:41 â€¢ 0:09:32\u001b[0m \u001b[37m0.95it/s\u001b[0m \u001b[37mloss: 11.9 v_num:\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0/99\u001b[0m \u001b[35mâ”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m40/571\u001b[0m \u001b[37m0:00:41 â€¢ 0:09:17\u001b[0m \u001b[37m0.95it/s\u001b[0m \u001b[37mloss: 11.9 v_num:\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0/99\u001b[0m \u001b[35mâ”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m40/571\u001b[0m \u001b[37m0:00:41 â€¢ 0:09:17\u001b[0m \u001b[37m0.95it/s\u001b[0m \u001b[37mloss: 11.9 v_num:\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0/99\u001b[0m \u001b[35mâ”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m40/571\u001b[0m \u001b[37m0:00:42 â€¢ 0:09:17\u001b[0m \u001b[37m0.95it/s\u001b[0m \u001b[37mloss: 11.9 v_num:\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0/99\u001b[0m \u001b[35mâ”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m40/571\u001b[0m \u001b[37m0:00:44 â€¢ 0:09:17\u001b[0m \u001b[37m0.95it/s\u001b[0m \u001b[37mloss: 11.9 v_num:\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0/99\u001b[0m \u001b[35mâ”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m40/571\u001b[0m \u001b[37m0:00:45 â€¢ 0:09:17\u001b[0m \u001b[37m0.95it/s\u001b[0m \u001b[37mloss: 11.7 v_num:\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0/99\u001b[0m \u001b[35mâ”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m40/571\u001b[0m \u001b[37m0:00:46 â€¢ 0:09:17\u001b[0m \u001b[37m0.95it/s\u001b[0m \u001b[37mloss: 11.5 v_num:\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0/99\u001b[0m \u001b[35mâ”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m40/571\u001b[0m \u001b[37m0:00:47 â€¢ 0:09:17\u001b[0m \u001b[37m0.95it/s\u001b[0m \u001b[37mloss: 11.4 v_num:\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0/99\u001b[0m \u001b[35mâ”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m40/571\u001b[0m \u001b[37m0:00:49 â€¢ 0:09:17\u001b[0m \u001b[37m0.95it/s\u001b[0m \u001b[37mloss: 11.2 v_num:\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0/99\u001b[0m \u001b[35mâ”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m40/571\u001b[0m \u001b[37m0:00:50 â€¢ 0:09:17\u001b[0m \u001b[37m0.95it/s\u001b[0m \u001b[37mloss: 11.3 v_num:\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0/99\u001b[0m \u001b[35mâ”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m40/571\u001b[0m \u001b[37m0:00:51 â€¢ 0:09:17\u001b[0m \u001b[37m0.95it/s\u001b[0m \u001b[37mloss: 11.3 v_num:\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0/99\u001b[0m \u001b[35mâ”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m40/571\u001b[0m \u001b[37m0:00:52 â€¢ 0:09:17\u001b[0m \u001b[37m0.95it/s\u001b[0m \u001b[37mloss: 11.2 v_num:\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0/99\u001b[0m \u001b[35mâ”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m50/571\u001b[0m \u001b[37m0:00:53 â€¢ 0:09:22\u001b[0m \u001b[37m0.93it/s\u001b[0m \u001b[37mloss: 11.2 v_num:\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0/99\u001b[0m \u001b[35mâ”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m50/571\u001b[0m \u001b[37m0:00:53 â€¢ 0:09:22\u001b[0m \u001b[37m0.93it/s\u001b[0m \u001b[37mloss: 11.2 v_num:\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0/99\u001b[0m \u001b[35mâ”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m50/571\u001b[0m \u001b[37m0:00:54 â€¢ 0:09:22\u001b[0m \u001b[37m0.93it/s\u001b[0m \u001b[37mloss: 11.1 v_num:\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0/99\u001b[0m \u001b[35mâ”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m50/571\u001b[0m \u001b[37m0:00:55 â€¢ 0:09:22\u001b[0m \u001b[37m0.93it/s\u001b[0m \u001b[37mloss: 11 v_num:  \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0/99\u001b[0m \u001b[35mâ”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m50/571\u001b[0m \u001b[37m0:00:56 â€¢ 0:09:22\u001b[0m \u001b[37m0.93it/s\u001b[0m \u001b[37mloss: 11 v_num:  \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0/99\u001b[0m \u001b[35mâ”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m50/571\u001b[0m \u001b[37m0:00:57 â€¢ 0:09:22\u001b[0m \u001b[37m0.93it/s\u001b[0m \u001b[37mloss: 10.8 v_num:\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0/99\u001b[0m \u001b[35mâ”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m50/571\u001b[0m \u001b[37m0:00:58 â€¢ 0:09:22\u001b[0m \u001b[37m0.93it/s\u001b[0m \u001b[37mloss: 10.8 v_num:\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0/99\u001b[0m \u001b[35mâ”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m50/571\u001b[0m \u001b[37m0:00:59 â€¢ 0:09:22\u001b[0m \u001b[37m0.93it/s\u001b[0m \u001b[37mloss: 10.7 v_num:\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0/99\u001b[0m \u001b[35mâ”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m50/571\u001b[0m \u001b[37m0:01:00 â€¢ 0:09:22\u001b[0m \u001b[37m0.93it/s\u001b[0m \u001b[37mloss: 10.7 v_num:\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0/99\u001b[0m \u001b[35mâ”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m50/571\u001b[0m \u001b[37m0:01:02 â€¢ 0:09:22\u001b[0m \u001b[37m0.93it/s\u001b[0m \u001b[37mloss: 10.5 v_num:\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0/99\u001b[0m \u001b[35mâ”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m50/571\u001b[0m \u001b[37m0:01:03 â€¢ 0:09:22\u001b[0m \u001b[37m0.93it/s\u001b[0m \u001b[37mloss: 10.5 v_num:\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0/99\u001b[0m \u001b[35mâ”\u001b[0m\u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m60/571\u001b[0m \u001b[37m0:01:04 â€¢ 0:09:36\u001b[0m \u001b[37m0.89it/s\u001b[0m \u001b[37mloss: 10.5 v_num:\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0/99\u001b[0m \u001b[35mâ”\u001b[0m\u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m60/571\u001b[0m \u001b[37m0:01:04 â€¢ 0:09:36\u001b[0m \u001b[37m0.89it/s\u001b[0m \u001b[37mloss: 10.4 v_num:\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0/99\u001b[0m \u001b[35mâ”\u001b[0m\u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m60/571\u001b[0m \u001b[37m0:01:05 â€¢ 0:09:36\u001b[0m \u001b[37m0.89it/s\u001b[0m \u001b[37mloss: 10.4 v_num:\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0/99\u001b[0m \u001b[35mâ”\u001b[0m\u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m60/571\u001b[0m \u001b[37m0:01:06 â€¢ 0:09:36\u001b[0m \u001b[37m0.89it/s\u001b[0m \u001b[37mloss: 10.5 v_num:\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0/99\u001b[0m \u001b[35mâ”\u001b[0m\u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m60/571\u001b[0m \u001b[37m0:01:07 â€¢ 0:09:36\u001b[0m \u001b[37m0.89it/s\u001b[0m \u001b[37mloss: 10.4 v_num:\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0/99\u001b[0m \u001b[35mâ”\u001b[0m\u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m60/571\u001b[0m \u001b[37m0:01:08 â€¢ 0:09:36\u001b[0m \u001b[37m0.89it/s\u001b[0m \u001b[37mloss: 10.4 v_num:\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0/99\u001b[0m \u001b[35mâ”\u001b[0m\u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m60/571\u001b[0m \u001b[37m0:01:09 â€¢ 0:09:36\u001b[0m \u001b[37m0.89it/s\u001b[0m \u001b[37mloss: 10.5 v_num:\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0/99\u001b[0m \u001b[35mâ”\u001b[0m\u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m60/571\u001b[0m \u001b[37m0:01:10 â€¢ 0:09:36\u001b[0m \u001b[37m0.89it/s\u001b[0m \u001b[37mloss: 10.5 v_num:\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0/99\u001b[0m \u001b[35mâ”\u001b[0m\u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m60/571\u001b[0m \u001b[37m0:01:11 â€¢ 0:09:36\u001b[0m \u001b[37m0.89it/s\u001b[0m \u001b[37mloss: 10.3 v_num:\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0/99\u001b[0m \u001b[35mâ”\u001b[0m\u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m60/571\u001b[0m \u001b[37m0:01:13 â€¢ 0:09:36\u001b[0m \u001b[37m0.89it/s\u001b[0m \u001b[37mloss: 10.2 v_num:\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0/99\u001b[0m \u001b[35mâ”\u001b[0m\u001b[35mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m60/571\u001b[0m \u001b[37m0:01:14 â€¢ 0:09:36\u001b[0m \u001b[37m0.89it/s\u001b[0m \u001b[37mloss: 10.2 v_num:\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0/99\u001b[0m \u001b[35mâ”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m70/571\u001b[0m \u001b[37m0:01:15 â€¢ 0:09:21\u001b[0m \u001b[37m0.89it/s\u001b[0m \u001b[37mloss: 10.2 v_num:\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0/99\u001b[0m \u001b[35mâ”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m70/571\u001b[0m \u001b[37m0:01:15 â€¢ 0:09:21\u001b[0m \u001b[37m0.89it/s\u001b[0m \u001b[37mloss: 10.1 v_num:\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0/99\u001b[0m \u001b[35mâ”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m70/571\u001b[0m \u001b[37m0:01:16 â€¢ 0:09:21\u001b[0m \u001b[37m0.89it/s\u001b[0m \u001b[37mloss: 10.1 v_num:\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0/99\u001b[0m \u001b[35mâ”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m70/571\u001b[0m \u001b[37m0:01:18 â€¢ 0:09:21\u001b[0m \u001b[37m0.89it/s\u001b[0m \u001b[37mloss: 9.88 v_num:\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0/99\u001b[0m \u001b[35mâ”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m70/571\u001b[0m \u001b[37m0:01:19 â€¢ 0:09:21\u001b[0m \u001b[37m0.89it/s\u001b[0m \u001b[37mloss: 9.74 v_num:\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0/99\u001b[0m \u001b[35mâ”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m70/571\u001b[0m \u001b[37m0:01:20 â€¢ 0:09:21\u001b[0m \u001b[37m0.89it/s\u001b[0m \u001b[37mloss: 9.76 v_num:\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0/99\u001b[0m \u001b[35mâ”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m70/571\u001b[0m \u001b[37m0:01:21 â€¢ 0:09:21\u001b[0m \u001b[37m0.89it/s\u001b[0m \u001b[37mloss: 9.65 v_num:\u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0/99\u001b[0m \u001b[35mâ”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m70/571\u001b[0m \u001b[37m0:01:22 â€¢ 0:09:21\u001b[0m \u001b[37m0.89it/s\u001b[0m \u001b[37mloss: 9.7 v_num: \u001b[0m\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[37mEpoch 0/99\u001b[0m \u001b[35mâ”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[37m70/571\u001b[0m \u001b[37m0:01:23 â€¢ 0:09:21\u001b[0m \u001b[37m0.89it/s\u001b[0m \u001b[37mloss: 9.66 v_num:\u001b[0m\n",
            "                                                               \u001b[37mon_1             \u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing"
      ],
      "metadata": {
        "id": "QJ6pT6-Nj6N9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "eval \"$(conda shell.bash hook)\"\n",
        "conda activate advanced_grapher_env\n",
        "\n",
        "! python main.py  --version 1\\\n",
        "                  --default_root_dir output \\\n",
        "                  --run test \\\n",
        "                  --max_epochs 200 \\\n",
        "                  --accelerator gpu \\\n",
        "                  --num_nodes 1 \\\n",
        "                  --devices \"1,\" \\\n",
        "                  --num_data_workers 32 \\\n",
        "                  --lr 5e-4 \\\n",
        "                  --batch_size 150 \\\n",
        "                  --num_sanity_val_steps 0 \\\n",
        "                  --fast_dev_run 0 \\\n",
        "                  --overfit_batches 0 \\\n",
        "                  --limit_train_batches 1.0 \\\n",
        "                  --limit_val_batches 1.0 \\\n",
        "                  --limit_test_batches 1.0 \\\n",
        "                  --accumulate_grad_batches 1 \\\n",
        "                  --detect_anomaly True \\\n",
        "                  --data_path webnlg-dataset/release_v3.0/en \\\n",
        "                  --val_check_interval 1.0 \\\n",
        "                  --focal_loss_gamma 3 \\\n",
        "                  --dropout_rate 0.5 \\\n",
        "                  --num_layers 2 \\\n",
        "                  --checkpoint_model_id -1 \\\n",
        "                  --precision \"bf16\" \\\n",
        "                  # --add-rgcn  \\\n",
        "\n",
        "\n",
        "                  # set add_rgcn flag if you want to train rgcn"
      ],
      "metadata": {
        "id": "vXNnIlghj7Nx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}