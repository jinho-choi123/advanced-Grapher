{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyMeNgOQRH55OLhnqWBzG+VC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jinho-choi123/advanced-Grapher/blob/artifact-evaluation/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "7m-Qpa3sjKaF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C3SYImfQTjNI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51e9a17c-cc02-440e-9a85-88c644bb804d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚è¨ Downloading https://github.com/jaimergp/miniforge/releases/download/24.11.2-1_colab/Miniforge3-colab-24.11.2-1_colab-Linux-x86_64.sh...\n",
            "üì¶ Installing...\n",
            "üìå Adjusting configuration...\n",
            "ü©π Patching environment...\n",
            "‚è≤ Done in 0:00:06\n",
            "üîÅ Restarting kernel...\n"
          ]
        }
      ],
      "source": [
        "# Install Colab Conda\n",
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Git clone https://github.com/jinho-choi123/advanced-Grapher.git\n",
        "!GIT_LFS_SKIP_SMUDGE=1 git clone https://github.com/jinho-choi123/advanced-Grapher.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rs2WemMUjQ1E",
        "outputId": "5801f109-24ea-478c-8244-3d1669c0d851"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'advanced-Grapher'...\n",
            "remote: Enumerating objects: 276, done.\u001b[K\n",
            "remote: Counting objects: 100% (67/67), done.\u001b[K\n",
            "remote: Compressing objects: 100% (46/46), done.\u001b[K\n",
            "remote: Total 276 (delta 44), reused 21 (delta 21), pack-reused 209 (from 2)\u001b[K\n",
            "Receiving objects: 100% (276/276), 21.76 MiB | 46.61 MiB/s, done.\n",
            "Resolving deltas: 100% (146/146), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# install conda dependencies\n",
        "%cd advanced-Grapher\n",
        "\n",
        "!conda env create -q -f requirements.yml -n advanced_grapher_env"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0munEtujSCr",
        "outputId": "647369b7-1699-4fd4-80ea-09769b1a8958"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/advanced-Grapher\n",
            "Channels:\n",
            " - pytorch\n",
            " - nvidia\n",
            " - conda-forge\n",
            " - defaults\n",
            "Platform: linux-64\n",
            "Collecting package metadata (repodata.json): ...working... done\n",
            "Solving environment: ...working... done\n",
            "Preparing transaction: ...working... done\n",
            "Verifying transaction: ...working... done\n",
            "Executing transaction: ...working... done\n",
            "Installing pip dependencies: ...working... done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "eval \"$(conda shell.bash hook)\"\n",
        "conda activate advanced_grapher_env"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebhEVyc4oRIH",
        "outputId": "42e403b5-a3c1-4db5-fb40-491435a2753c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# install datasets and dataset reader\n",
        "!git clone https://gitlab.com/webnlg/corpus-reader.git corpusreader\n",
        "!git clone https://gitlab.com/shimorina/webnlg-dataset.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JrAXHlszjq1q",
        "outputId": "c638f1a6-714d-4096-f3d7-81faf4bac620"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'corpusreader'...\n",
            "remote: Enumerating objects: 21, done.\u001b[K\n",
            "remote: Total 21 (delta 0), reused 0 (delta 0), pack-reused 21 (from 1)\u001b[K\n",
            "Receiving objects: 100% (21/21), 7.88 KiB | 7.88 MiB/s, done.\n",
            "Resolving deltas: 100% (9/9), done.\n",
            "Cloning into 'webnlg-dataset'...\n",
            "remote: Enumerating objects: 5112, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 5112 (delta 2), reused 0 (delta 0), pack-reused 5106 (from 1)\u001b[K\n",
            "Receiving objects: 100% (5112/5112), 26.09 MiB | 24.60 MiB/s, done.\n",
            "Resolving deltas: 100% (4010/4010), done.\n",
            "Updating files: 100% (1425/1425), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "2b389hyrjvjJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "eval \"$(conda shell.bash hook)\"\n",
        "conda activate advanced_grapher_env\n",
        "\n",
        "# Actual Training happens here\n",
        "python main.py    --version 1\\\n",
        "                  --default_root_dir output \\\n",
        "                  --run train \\\n",
        "                  --max_epochs 100 \\\n",
        "                  --accelerator gpu \\\n",
        "                  --num_nodes 1 \\\n",
        "                  --devices \"0,\" \\\n",
        "                  --num_data_workers 12 \\\n",
        "                  --lr 1e-4 \\\n",
        "                  --batch_size 200 \\\n",
        "                  --num_sanity_val_steps 10 \\\n",
        "                  --fast_dev_run 0 \\\n",
        "                  --overfit_batches 0 \\\n",
        "                  --limit_train_batches 1.0 \\\n",
        "                  --limit_val_batches 1.0 \\\n",
        "                  --limit_test_batches 1.0 \\\n",
        "                  --accumulate_grad_batches 1 \\\n",
        "                  --detect_anomaly True \\\n",
        "                  --data_path webnlg-dataset/release_v3.0/en \\\n",
        "                  --val_check_interval 1.0 \\\n",
        "                  --focal_loss_gamma 3 \\\n",
        "                  --dropout_rate 0.5 \\\n",
        "                  --num_layers 2 \\\n",
        "                  --edges_as_classes 1 \\\n",
        "                  --checkpoint_model_id -1 \\\n",
        "                  --check_val_every_n_epoch 10 \\\n",
        "                  # --add-rgcn\n",
        "\n",
        "\n",
        "                  # set add_rgcn flag if you want to test with rgcn added\n",
        "                  # if add_rgcn flag is set, we should reduce batch_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dh8I-mGljxEG",
        "outputId": "33dc85bd-475c-4be4-b05b-e4ab077c2592"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "('arguments: \\n'\n",
            " \"Namespace(dataset='webnlg', run='train', pretrained_model='t5-small', \"\n",
            " \"version='1', data_path='webnlg-dataset/release_v3.0/en', cache_dir='cache', \"\n",
            " 'num_data_workers=12, checkpoint_model_id=-1, max_nodes=8, max_edges=7, '\n",
            " 'default_seq_len_node=20, default_seq_len_edge=20, edges_as_classes=1, '\n",
            " 'batch_size=200, lr=0.0001, focal_loss_gamma=3.0, dropout_rate=0.5, '\n",
            " \"num_layers=2, eval_dump_only=0, inference_input_text='Danielle Harris had a \"\n",
            " \"main role in Super Capers, a 98 minute long movie.', model_max_length=512, \"\n",
            " 'rgcn_layers_num=2, rgcn_hidden_dim=128, add_rgcn=False, logger=True, '\n",
            " \"enable_checkpointing=True, default_root_dir='output', \"\n",
            " 'gradient_clip_val=None, gradient_clip_algorithm=None, num_nodes=1, '\n",
            " \"num_processes=None, devices='0,', gpus=None, auto_select_gpus=False, \"\n",
            " 'tpu_cores=None, ipus=None, enable_progress_bar=True, overfit_batches=0, '\n",
            " 'track_grad_norm=-1, check_val_every_n_epoch=10, fast_dev_run=False, '\n",
            " 'accumulate_grad_batches=1, max_epochs=100, min_epochs=None, max_steps=-1, '\n",
            " 'min_steps=None, max_time=None, limit_train_batches=1.0, '\n",
            " 'limit_val_batches=1.0, limit_test_batches=1.0, limit_predict_batches=None, '\n",
            " \"val_check_interval=1.0, log_every_n_steps=50, accelerator='gpu', \"\n",
            " 'strategy=None, sync_batchnorm=False, precision=32, '\n",
            " 'enable_model_summary=True, num_sanity_val_steps=10, '\n",
            " 'resume_from_checkpoint=None, profiler=None, benchmark=None, '\n",
            " 'deterministic=None, reload_dataloaders_every_n_epochs=0, auto_lr_find=False, '\n",
            " 'replace_sampler_ddp=True, detect_anomaly=True, auto_scale_batch_size=False, '\n",
            " \"plugins=None, amp_backend='native', amp_level=None, \"\n",
            " \"move_metrics_to_cpu=False, multiple_trainloader_mode='max_size_cycle', \"\n",
            " 'inference_mode=True)')\n",
            "TRAIN MODE\n",
            "ModelCheckpoint(save_last=True, save_top_k=-1, monitor=None) will duplicate the last checkpoint saved.\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "`Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..\n",
            "`Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..\n",
            "`Trainer(limit_test_batches=1.0)` was configured so 100% of the batches will be used..\n",
            "`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n",
            "/usr/local/envs/advanced_grapher_env/lib/python3.9/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:601: UserWarning: Checkpoint directory output/webnlg_version_1/checkpoints exists and is not empty.\n",
            "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
            "Restoring states from the checkpoint path at output/webnlg_version_1/checkpoints/last.ckpt\n",
            "/usr/local/envs/advanced_grapher_env/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1401: UserWarning: Be aware that when using `ckpt_path`, callbacks used to create the checkpoint need to be provided during `Trainer` instantiation. Please add the following callbacks: [\"ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None, 'save_on_train_epoch_end': True}\"].\n",
            "  rank_zero_warn(\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "‚îè‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
            "‚îÉ\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m‚îÉ\u001b[1;35m \u001b[0m\u001b[1;35mName \u001b[0m\u001b[1;35m \u001b[0m‚îÉ\u001b[1;35m \u001b[0m\u001b[1;35mType   \u001b[0m\u001b[1;35m \u001b[0m‚îÉ\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m‚îÉ\n",
            "‚î°‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
            "‚îÇ\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m‚îÇ model ‚îÇ Grapher ‚îÇ 61.3 M ‚îÇ\n",
            "‚îî‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
            "\u001b[1mTrainable params\u001b[0m: 61.3 M                                                        \n",
            "\u001b[1mNon-trainable params\u001b[0m: 0                                                         \n",
            "\u001b[1mTotal params\u001b[0m: 61.3 M                                                            \n",
            "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 245                                     \n",
            "Restored all states from the checkpoint file at output/webnlg_version_1/checkpoints/last.ckpt\n",
            "\u001b[2K"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing"
      ],
      "metadata": {
        "id": "QJ6pT6-Nj6N9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "eval \"$(conda shell.bash hook)\"\n",
        "conda activate advanced_grapher_env\n",
        "\n",
        "! python main.py  --version 1\\\n",
        "                  --default_root_dir output \\\n",
        "                  --run test \\\n",
        "                  --max_epochs 200 \\\n",
        "                  --accelerator gpu \\\n",
        "                  --num_nodes 1 \\\n",
        "                  --devices \"1,\" \\\n",
        "                  --num_data_workers 32 \\\n",
        "                  --lr 5e-4 \\\n",
        "                  --batch_size 150 \\\n",
        "                  --num_sanity_val_steps 0 \\\n",
        "                  --fast_dev_run 0 \\\n",
        "                  --overfit_batches 0 \\\n",
        "                  --limit_train_batches 1.0 \\\n",
        "                  --limit_val_batches 1.0 \\\n",
        "                  --limit_test_batches 1.0 \\\n",
        "                  --accumulate_grad_batches 1 \\\n",
        "                  --detect_anomaly True \\\n",
        "                  --data_path webnlg-dataset/release_v3.0/en \\\n",
        "                  --val_check_interval 1.0 \\\n",
        "                  --focal_loss_gamma 3 \\\n",
        "                  --dropout_rate 0.5 \\\n",
        "                  --num_layers 2 \\\n",
        "                  --checkpoint_model_id -1 \\\n",
        "                  --precision \"bf16\" \\\n",
        "                  # --add-rgcn  \\\n",
        "\n",
        "\n",
        "                  # set add_rgcn flag if you want to train rgcn"
      ],
      "metadata": {
        "id": "vXNnIlghj7Nx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}